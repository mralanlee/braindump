# S3 - Simple Storage Service

Secure, durable, highly-scable object storage.

- Safe place to store files
- Object-based storage
- Data is spread across multiple devices and facilities

### S3 Basics
- Object-based, allows you to upload files
- Files can be from 0 bytes to 5TB
- Unlimited storage
- Files are stored in buckets
- Buckets have a universal namespace. Bucket names have to be globally unique
- URL: https://s3-<region>.amazonaws.com/<bucketName>
- When a file is uploaded to S3, a 200 code is replied if successful.

### Data consistency
- Read after write consistency for PUTS of new objects
- Eventual consistency for overwrite PUTs and DELETEs

### Key Value Store
- Key: Name of object, Value: data/bytes
- Version ID
- Metadata, data about files
- Subresources
-- Access control list
-- Torrent

#### Benefits
-- Built for 99.99% availability
-- Amazon guarantess 99.9% availability
-- Amazon guarantess 99.9999999999% (11 x 9) durability for S3 info
-- Tiered storage classses available
-- Lifecycle Management (Glacier)
-- Versioning
-- Encryption
-- Secure data using Access Control List and Bucket Policies

## Storage Tiers
* S3 Standard
  -- 99.99% availability
  -- 99.9999999999% (11 x 9) durability
  -- Redundantly across multiple devices in multiple facilities
  -- Designed to sustain the loss of 2 facilities concurrently
* S3-IA (Infrequently Accessed)
  -- Less frequently
  -- Rapid access when needed
  -- Lower fees than S3, but charged retrieval fee
* S3-IA (One Zone)
  -- Lower-cost option for IA data, but no multiple availability zone data resilience. 
* Glacier
  -- Very Cheap, but for archival only. Expedited, standard or bulk. Retrieval time takes 3-5 hours.
  
#### Charges
- Storage
- Requests
- Storage Management Pricing (tagging)
- Data Transfer Pricing (cross region data replication)
- Transfer Acceralation (fast, easy and secure over long distances between end users and s3)

## Cross Region Replication
* Versioning must be enabled on both source and destination
* Regionst must be unique
* Files in an existing bucket are not replicated automatically. 
* Cannot replicate to multiple buckets or use daisy chaining
* Delete markers are replicated
* Deleting individual versions or delete markers will not be replicated

## Glacier
* Can be used in conjunction with versioning
* Can be applied to current or previous versions.
* Following actions can be done:
  * Transition to the standard - infrequent access storage class
  * archive to glacier storage class
  * permanently delete

## CloudFront
* Edge Location - Location where content will be cached.

## Security and Encryption
* By default, all newly created buckets are PRIVATE
* Setup access control to your buckets using:
  * Bucket policies
  * Access Control Lists
* Buckets can be configured to create access logs

### Encryption
In transit:
  * SSL/TLS
  * at REST
    * Server Side Encryption
    * S3 managed Keys - SSE-S3 (AES-256)
    * AWS KMS, managed keys
      * Provides audit trail, of who is decrypting what and when
      * Can be based on region
    * Server side Encryption with customer provided keys - SSE-C
      * Managed by you
  * Client side encryption

## S3 Transfer Acceleration
- Utilizes CloudFront Edge network to accelerate uploads to S3.
- Instead of uploading directly to S3 bucket, you can use a distinct URL to upload directly to an edge location that will transfer to S3.
- <bucketName>.s3-accelerate.amazonaws.com

## S3 Website/Static hosting
  Endpoint: bucketname.s3-website-region.amazonaws.com
  
  
When trying to grant an amazon account access to S3 using access control lists, email address or canonical user ID
